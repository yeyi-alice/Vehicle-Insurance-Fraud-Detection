{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>Year</th>\n",
       "      <th>BasePolicy</th>\n",
       "      <th>Date</th>\n",
       "      <th>DateClaimed</th>\n",
       "      <th>Date_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "      <td>1994-12-29</td>\n",
       "      <td>1994-01-05</td>\n",
       "      <td>-358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1994-01-20</td>\n",
       "      <td>1994-01-25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1994-10-29</td>\n",
       "      <td>1994-11-11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Liability</td>\n",
       "      <td>1994-06-12</td>\n",
       "      <td>1994-07-02</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Urban</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1994</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1994-02-01</td>\n",
       "      <td>1994-02-09</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15414</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>none</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1996-11-23</td>\n",
       "      <td>1996-12-04</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15415</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Pontiac</td>\n",
       "      <td>Urban</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>3 to 4</td>\n",
       "      <td>1996</td>\n",
       "      <td>Liability</td>\n",
       "      <td>1996-11-29</td>\n",
       "      <td>1996-12-07</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15416</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Rural</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1996-11-29</td>\n",
       "      <td>1996-12-07</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>more than 5</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>All Perils</td>\n",
       "      <td>1996-12-03</td>\n",
       "      <td>1996-12-13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Urban</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>External</td>\n",
       "      <td>1 to 2</td>\n",
       "      <td>no change</td>\n",
       "      <td>1 vehicle</td>\n",
       "      <td>1996</td>\n",
       "      <td>Collision</td>\n",
       "      <td>1996-12-12</td>\n",
       "      <td>1996-12-20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15419 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  WeekOfMonth  DayOfWeek     Make AccidentArea  DayOfWeekClaimed  \\\n",
       "0         12            5          3    Honda        Urban                 2   \n",
       "1          1            3          3    Honda        Urban                 1   \n",
       "2         10            5          5    Honda        Urban                 4   \n",
       "3          6            2          6   Toyota        Rural                 5   \n",
       "4          1            5          1    Honda        Urban                 2   \n",
       "...      ...          ...        ...      ...          ...               ...   \n",
       "15414     11            4          5   Toyota        Urban                 2   \n",
       "15415     11            5          4  Pontiac        Urban                 5   \n",
       "15416     11            5          4   Toyota        Rural                 5   \n",
       "15417     12            1          1   Toyota        Urban                 4   \n",
       "15418     12            2          3   Toyota        Urban                 4   \n",
       "\n",
       "       MonthClaimed  WeekOfMonthClaimed     Sex MaritalStatus  ...  \\\n",
       "0                 1                   1  Female        Single  ...   \n",
       "1                 1                   4    Male        Single  ...   \n",
       "2                11                   2    Male       Married  ...   \n",
       "3                 7                   1    Male       Married  ...   \n",
       "4                 2                   2  Female        Single  ...   \n",
       "...             ...                 ...     ...           ...  ...   \n",
       "15414            11                   5    Male       Married  ...   \n",
       "15415            12                   1    Male       Married  ...   \n",
       "15416            12                   1    Male        Single  ...   \n",
       "15417            12                   2  Female       Married  ...   \n",
       "15418            12                   3    Male        Single  ...   \n",
       "\n",
       "       WitnessPresent AgentType NumberOfSuppliments AddressChange_Claim  \\\n",
       "0                  No  External                none              1 year   \n",
       "1                  No  External                none           no change   \n",
       "2                  No  External                none           no change   \n",
       "3                  No  External         more than 5           no change   \n",
       "4                  No  External                none           no change   \n",
       "...               ...       ...                 ...                 ...   \n",
       "15414              No  External                none           no change   \n",
       "15415              No  External         more than 5           no change   \n",
       "15416              No  External              1 to 2           no change   \n",
       "15417              No  External         more than 5           no change   \n",
       "15418              No  External              1 to 2           no change   \n",
       "\n",
       "      NumberOfCars  Year  BasePolicy       Date  DateClaimed  Date_Diff  \n",
       "0           3 to 4  1994   Liability 1994-12-29   1994-01-05       -358  \n",
       "1        1 vehicle  1994   Collision 1994-01-20   1994-01-25          5  \n",
       "2        1 vehicle  1994   Collision 1994-10-29   1994-11-11         13  \n",
       "3        1 vehicle  1994   Liability 1994-06-12   1994-07-02         20  \n",
       "4        1 vehicle  1994   Collision 1994-02-01   1994-02-09          8  \n",
       "...            ...   ...         ...        ...          ...        ...  \n",
       "15414    1 vehicle  1996   Collision 1996-11-23   1996-12-04         11  \n",
       "15415       3 to 4  1996   Liability 1996-11-29   1996-12-07          8  \n",
       "15416    1 vehicle  1996   Collision 1996-11-29   1996-12-07          8  \n",
       "15417    1 vehicle  1996  All Perils 1996-12-03   1996-12-13         10  \n",
       "15418    1 vehicle  1996   Collision 1996-12-12   1996-12-20          8  \n",
       "\n",
       "[15419 rows x 36 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data_new.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5      206\n",
       "-6      203\n",
       "-4      169\n",
       "-3      146\n",
       "-2      119\n",
       "       ... \n",
       "-260      1\n",
       "-334      1\n",
       "-271      1\n",
       "-238      1\n",
       "-270      1\n",
       "Name: Date_Diff, Length: 183, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handle abnormal values: negative date_diff\n",
    "data[data['Date_Diff']<0]['Date_Diff'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.8400e+02, 7.2000e+01, 4.0000e+01, 2.2000e+01, 5.8900e+02,\n",
       "        1.4043e+04, 2.0300e+02, 3.6000e+01, 2.7000e+01, 3.0000e+00]),\n",
       " array([-368. , -295.1, -222.2, -149.3,  -76.4,   -3.5,   69.4,  142.3,\n",
       "         215.2,  288.1,  361. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['Date_Diff'], color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histogram, we could observe that most of Date_diff values are around 0 to 100. Values less than -300 are likely to be representing that claims were made in the next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.3454e+04, 6.3500e+02, 1.9000e+02, 8.1000e+01, 3.5000e+01,\n",
       "        4.1000e+01, 3.2000e+01, 1.6000e+01, 7.0000e+00, 9.2800e+02]),\n",
       " array([ -3. ,  33.7,  70.4, 107.1, 143.8, 180.5, 217.2, 253.9, 290.6,\n",
       "        327.3, 364. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.loc[data['Date_Diff'] < 0, 'Date_Diff'] += 365\n",
    "plt.hist(data['Date_Diff'], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = data['Date_Diff']>300\n",
    "data = data[~outlier] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns\n",
    "data = data.drop(['Date', 'DateClaimed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PolicyNumber'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Month', 'WeekOfMonth', 'DayOfWeek', 'Make', 'AccidentArea',\n",
       "       'DayOfWeekClaimed', 'MonthClaimed', 'WeekOfMonthClaimed', 'Sex',\n",
       "       'MaritalStatus', 'Age', 'Fault', 'PolicyType', 'VehicleCategory',\n",
       "       'VehiclePrice', 'FraudFound_P', 'RepNumber', 'Deductible',\n",
       "       'DriverRating', 'Days_Policy_Accident', 'Days_Policy_Claim',\n",
       "       'PastNumberOfClaims', 'AgeOfVehicle', 'AgeOfPolicyHolder',\n",
       "       'PoliceReportFiled', 'WitnessPresent', 'AgentType',\n",
       "       'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'Year',\n",
       "       'BasePolicy', 'Date_Diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values for Make: 19\n",
      "Number of distinct values for AccidentArea: 2\n",
      "Number of distinct values for Sex: 2\n",
      "Number of distinct values for MaritalStatus: 4\n",
      "Number of distinct values for Fault: 2\n",
      "Number of distinct values for PolicyType: 9\n",
      "Number of distinct values for VehicleCategory: 3\n",
      "Number of distinct values for VehiclePrice: 6\n",
      "Number of distinct values for Days_Policy_Accident: 5\n",
      "Number of distinct values for Days_Policy_Claim: 3\n",
      "Number of distinct values for PastNumberOfClaims: 4\n",
      "Number of distinct values for AgeOfVehicle: 8\n",
      "Number of distinct values for AgeOfPolicyHolder: 9\n",
      "Number of distinct values for PoliceReportFiled: 2\n",
      "Number of distinct values for WitnessPresent: 2\n",
      "Number of distinct values for AgentType: 2\n",
      "Number of distinct values for NumberOfSuppliments: 4\n",
      "Number of distinct values for AddressChange_Claim: 5\n",
      "Number of distinct values for NumberOfCars: 5\n",
      "Number of distinct values for BasePolicy: 3\n"
     ]
    }
   ],
   "source": [
    "# Overview of distinct values of each categorical variable\n",
    "categorical_val = ['Make', 'AccidentArea', 'Sex',\n",
    "       'MaritalStatus', 'Fault', 'PolicyType', 'VehicleCategory','VehiclePrice', 'Days_Policy_Accident',\n",
    "       'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle',\n",
    "       'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType',\n",
    "       'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars', 'BasePolicy']\n",
    "for column in categorical_val:\n",
    "    distinct_values = data[column].nunique()\n",
    "    print(f\"Number of distinct values for {column}: {distinct_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode binary classes\n",
    "label_encoder = LabelEncoder()\n",
    "binary_class = ['AccidentArea', 'Sex', 'Fault', 'PoliceReportFiled', 'WitnessPresent', 'AgentType']\n",
    "for column in binary_class:\n",
    "    data[column] = label_encoder.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.3591938155715\n"
     ]
    }
   ],
   "source": [
    "# PolicyType seems to be a combination of VehicleCategory and BasePolicy. Check any inconsistency.\n",
    "combination_type = data['VehicleCategory'] + ' - ' + data['BasePolicy']\n",
    "matching_values = data['PolicyType'] == combination_type\n",
    "\n",
    "# Calculate the percentage of matching values\n",
    "percentage_matching = (matching_values.sum() / len(data)) * 100\n",
    "print(percentage_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As almost 70% of PolicyType matches the combination of VehicleCategory and BasePolicy. There is high possibility of multicollinearity. \n",
    "# Therefore, PolicyType should be dropped and an additional column is created to indicate whether the original PolicyType value matches the combination of other two columns.\n",
    "data['Matching'] = matching_values.astype(int)\n",
    "data = data.drop(['PolicyType'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "15414    2\n",
       "15415    2\n",
       "15416    2\n",
       "15417    2\n",
       "15418    2\n",
       "Name: Year, Length: 14488, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map year\n",
    "data['Year'] = data['Year'].map({1994: 0, 1995: 1, 1996: 2})\n",
    "data['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>MonthClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>...</th>\n",
       "      <th>AddressChange_Claim_no change</th>\n",
       "      <th>AddressChange_Claim_under 6 months</th>\n",
       "      <th>NumberOfCars_1 vehicle</th>\n",
       "      <th>NumberOfCars_2 vehicles</th>\n",
       "      <th>NumberOfCars_3 to 4</th>\n",
       "      <th>NumberOfCars_5 to 8</th>\n",
       "      <th>NumberOfCars_more than 8</th>\n",
       "      <th>BasePolicy_All Perils</th>\n",
       "      <th>BasePolicy_Collision</th>\n",
       "      <th>BasePolicy_Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15414</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15415</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15416</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14488 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  WeekOfMonth  DayOfWeek  AccidentArea  DayOfWeekClaimed  \\\n",
       "0         12            5          3             1                 2   \n",
       "1          1            3          3             1                 1   \n",
       "2         10            5          5             1                 4   \n",
       "3          6            2          6             0                 5   \n",
       "4          1            5          1             1                 2   \n",
       "...      ...          ...        ...           ...               ...   \n",
       "15414     11            4          5             1                 2   \n",
       "15415     11            5          4             1                 5   \n",
       "15416     11            5          4             0                 5   \n",
       "15417     12            1          1             1                 4   \n",
       "15418     12            2          3             1                 4   \n",
       "\n",
       "       MonthClaimed  WeekOfMonthClaimed  Sex  Age  Fault  ...  \\\n",
       "0                 1                   1    0   21      0  ...   \n",
       "1                 1                   4    1   34      0  ...   \n",
       "2                11                   2    1   47      0  ...   \n",
       "3                 7                   1    1   65      1  ...   \n",
       "4                 2                   2    0   27      1  ...   \n",
       "...             ...                 ...  ...  ...    ...  ...   \n",
       "15414            11                   5    1   35      0  ...   \n",
       "15415            12                   1    1   30      0  ...   \n",
       "15416            12                   1    1   24      0  ...   \n",
       "15417            12                   2    0   34      1  ...   \n",
       "15418            12                   3    1   21      0  ...   \n",
       "\n",
       "       AddressChange_Claim_no change  AddressChange_Claim_under 6 months  \\\n",
       "0                                  0                                   0   \n",
       "1                                  1                                   0   \n",
       "2                                  1                                   0   \n",
       "3                                  1                                   0   \n",
       "4                                  1                                   0   \n",
       "...                              ...                                 ...   \n",
       "15414                              1                                   0   \n",
       "15415                              1                                   0   \n",
       "15416                              1                                   0   \n",
       "15417                              1                                   0   \n",
       "15418                              1                                   0   \n",
       "\n",
       "       NumberOfCars_1 vehicle  NumberOfCars_2 vehicles  NumberOfCars_3 to 4  \\\n",
       "0                           0                        0                    1   \n",
       "1                           1                        0                    0   \n",
       "2                           1                        0                    0   \n",
       "3                           1                        0                    0   \n",
       "4                           1                        0                    0   \n",
       "...                       ...                      ...                  ...   \n",
       "15414                       1                        0                    0   \n",
       "15415                       0                        0                    1   \n",
       "15416                       1                        0                    0   \n",
       "15417                       1                        0                    0   \n",
       "15418                       1                        0                    0   \n",
       "\n",
       "       NumberOfCars_5 to 8  NumberOfCars_more than 8  BasePolicy_All Perils  \\\n",
       "0                        0                         0                      0   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      0   \n",
       "3                        0                         0                      0   \n",
       "4                        0                         0                      0   \n",
       "...                    ...                       ...                    ...   \n",
       "15414                    0                         0                      0   \n",
       "15415                    0                         0                      0   \n",
       "15416                    0                         0                      0   \n",
       "15417                    0                         0                      1   \n",
       "15418                    0                         0                      0   \n",
       "\n",
       "       BasePolicy_Collision  BasePolicy_Liability  \n",
       "0                         0                     1  \n",
       "1                         1                     0  \n",
       "2                         1                     0  \n",
       "3                         0                     1  \n",
       "4                         1                     0  \n",
       "...                     ...                   ...  \n",
       "15414                     1                     0  \n",
       "15415                     0                     1  \n",
       "15416                     1                     0  \n",
       "15417                     0                     0  \n",
       "15418                     1                     0  \n",
       "\n",
       "[14488 rows x 98 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot encoding categorical variables\n",
    "onehot_variables = ['Make',\n",
    " 'MaritalStatus',\n",
    " 'VehicleCategory',\n",
    " 'VehiclePrice',\n",
    " 'Days_Policy_Accident',\n",
    " 'Days_Policy_Claim',\n",
    " 'PastNumberOfClaims',\n",
    " 'AgeOfVehicle',\n",
    " 'AgeOfPolicyHolder',\n",
    " 'NumberOfSuppliments',\n",
    " 'AddressChange_Claim',\n",
    " 'NumberOfCars',\n",
    " 'BasePolicy']\n",
    "\n",
    "one_hot_encoded = pd.get_dummies(data, columns=onehot_variables)\n",
    "\n",
    "one_hot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "x = one_hot_encoded.drop(['FraudFound_P'], axis = 1)\n",
    "y = one_hot_encoded['FraudFound_P']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060940735627650136\n",
      "0.062341844950540605\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.mean())\n",
    "print(Y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 3s 8ms/step - loss: 0.3090 - accuracy: 0.9098 - val_loss: 0.2004 - val_accuracy: 0.9458\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9375 - val_loss: 0.1861 - val_accuracy: 0.9458\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9377 - val_loss: 0.1828 - val_accuracy: 0.9448\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9381 - val_loss: 0.1798 - val_accuracy: 0.9428\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9382 - val_loss: 0.1790 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1729 - accuracy: 0.9387 - val_loss: 0.1789 - val_accuracy: 0.9438\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9387 - val_loss: 0.1816 - val_accuracy: 0.9399\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9401 - val_loss: 0.1804 - val_accuracy: 0.9428\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9401 - val_loss: 0.1793 - val_accuracy: 0.9423\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9416 - val_loss: 0.1832 - val_accuracy: 0.9423\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9430 - val_loss: 0.1824 - val_accuracy: 0.9428\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9444 - val_loss: 0.1851 - val_accuracy: 0.9423\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9463 - val_loss: 0.1855 - val_accuracy: 0.9433\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9467 - val_loss: 0.1872 - val_accuracy: 0.9428\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9474 - val_loss: 0.1893 - val_accuracy: 0.9428\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9485 - val_loss: 0.1927 - val_accuracy: 0.9409\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1295 - accuracy: 0.9502 - val_loss: 0.1935 - val_accuracy: 0.9409\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9524 - val_loss: 0.1956 - val_accuracy: 0.9404\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9536 - val_loss: 0.2002 - val_accuracy: 0.9409\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9538 - val_loss: 0.2061 - val_accuracy: 0.9418\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9544 - val_loss: 0.2059 - val_accuracy: 0.9433\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9561 - val_loss: 0.2097 - val_accuracy: 0.9315\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1113 - accuracy: 0.9577 - val_loss: 0.2132 - val_accuracy: 0.9330\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9578 - val_loss: 0.2194 - val_accuracy: 0.9364\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.1069 - accuracy: 0.9582 - val_loss: 0.2206 - val_accuracy: 0.9369\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9593 - val_loss: 0.2241 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1434d3b50>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=20,\n",
    "    restore_best_weights=True)\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 3ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      9523\n",
      "           1       0.61      0.03      0.06       618\n",
      "\n",
      "    accuracy                           0.94     10141\n",
      "   macro avg       0.78      0.51      0.51     10141\n",
      "weighted avg       0.92      0.94      0.91     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[9511   12]\n",
      " [ 599   19]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that recall for class 1 is very small. It is resulted from unbalanced dataset. \n",
    "Next, I will try to handle the unbalanced dataset with class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "127/127 [==============================] - 2s 8ms/step - loss: 0.5093 - accuracy: 0.7414 - val_loss: 0.5307 - val_accuracy: 0.6757\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7316 - val_loss: 0.5019 - val_accuracy: 0.7023\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.7427 - val_loss: 0.5043 - val_accuracy: 0.7151\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.7584 - val_loss: 0.4437 - val_accuracy: 0.7447\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.3561 - accuracy: 0.7744 - val_loss: 0.4220 - val_accuracy: 0.7575\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.7949 - val_loss: 0.3946 - val_accuracy: 0.7827\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8004 - val_loss: 0.3919 - val_accuracy: 0.7945\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8120 - val_loss: 0.4296 - val_accuracy: 0.7772\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8188 - val_loss: 0.4193 - val_accuracy: 0.7841\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.8306 - val_loss: 0.3981 - val_accuracy: 0.8063\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8463 - val_loss: 0.4590 - val_accuracy: 0.7723\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8503 - val_loss: 0.4127 - val_accuracy: 0.8019\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 0.8553 - val_loss: 0.3867 - val_accuracy: 0.8216\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2379 - accuracy: 0.8645 - val_loss: 0.3999 - val_accuracy: 0.8231\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.2284 - accuracy: 0.8709 - val_loss: 0.3759 - val_accuracy: 0.8364\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2200 - accuracy: 0.8776 - val_loss: 0.4576 - val_accuracy: 0.8024\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.2120 - accuracy: 0.8791 - val_loss: 0.4229 - val_accuracy: 0.8241\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.8873 - val_loss: 0.4067 - val_accuracy: 0.8349\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.8924 - val_loss: 0.4593 - val_accuracy: 0.8152\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.8987 - val_loss: 0.4253 - val_accuracy: 0.8344\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.1838 - accuracy: 0.9005 - val_loss: 0.4635 - val_accuracy: 0.8216\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9030 - val_loss: 0.4163 - val_accuracy: 0.8448\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9090 - val_loss: 0.4383 - val_accuracy: 0.8433\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9116 - val_loss: 0.4551 - val_accuracy: 0.8408\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9111 - val_loss: 0.4822 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9183 - val_loss: 0.4329 - val_accuracy: 0.8551\n",
      "Epoch 27/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9195 - val_loss: 0.4628 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9223 - val_loss: 0.4502 - val_accuracy: 0.8541\n",
      "Epoch 29/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9257 - val_loss: 0.4545 - val_accuracy: 0.8610\n",
      "Epoch 30/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9274 - val_loss: 0.4534 - val_accuracy: 0.8674\n",
      "Epoch 31/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9302 - val_loss: 0.4921 - val_accuracy: 0.8477\n",
      "Epoch 32/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9331 - val_loss: 0.5087 - val_accuracy: 0.8497\n",
      "Epoch 33/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9332 - val_loss: 0.5014 - val_accuracy: 0.8556\n",
      "Epoch 34/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9392 - val_loss: 0.5010 - val_accuracy: 0.8640\n",
      "Epoch 35/100\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9376 - val_loss: 0.5129 - val_accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1439601f0>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = np.unique(Y_train)\n",
    "class_weights = compute_class_weight(class_weight ='balanced',classes=np.unique(Y_train), y=Y_train)\n",
    "class_weights_dict = dict(zip(class_labels, class_weights))\n",
    "# Use class weights during model training\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2, class_weight=class_weights_dict, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 2ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      9523\n",
      "           1       0.32      0.89      0.47       618\n",
      "\n",
      "    accuracy                           0.88     10141\n",
      "   macro avg       0.66      0.88      0.70     10141\n",
      "weighted avg       0.95      0.88      0.90     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[8354 1169]\n",
      " [  71  547]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91      4076\n",
      "           1       0.19      0.50      0.27       271\n",
      "\n",
      "    accuracy                           0.83      4347\n",
      "   macro avg       0.57      0.68      0.59      4347\n",
      "weighted avg       0.91      0.83      0.87      4347\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3486  590]\n",
      " [ 136  135]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 2s 5ms/step - loss: 0.8109 - accuracy: 0.4831 - val_loss: 0.7158 - val_accuracy: 0.5175\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.5636 - val_loss: 0.6307 - val_accuracy: 0.5850\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6143 - val_loss: 0.5934 - val_accuracy: 0.6220\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6324 - val_loss: 0.5751 - val_accuracy: 0.6471\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.5635 - accuracy: 0.6499 - val_loss: 0.5606 - val_accuracy: 0.6599\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.6649 - val_loss: 0.5411 - val_accuracy: 0.6703\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.6922 - val_loss: 0.5318 - val_accuracy: 0.6777\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.6845 - val_loss: 0.5266 - val_accuracy: 0.6792\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.6898 - val_loss: 0.5158 - val_accuracy: 0.6811\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7002 - val_loss: 0.5053 - val_accuracy: 0.6836\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7014 - val_loss: 0.4950 - val_accuracy: 0.6865\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7043 - val_loss: 0.4808 - val_accuracy: 0.6925\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7129 - val_loss: 0.4750 - val_accuracy: 0.6875\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7098 - val_loss: 0.4881 - val_accuracy: 0.6821\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7096 - val_loss: 0.4812 - val_accuracy: 0.6782\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7072 - val_loss: 0.4677 - val_accuracy: 0.6885\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7156 - val_loss: 0.4673 - val_accuracy: 0.6915\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7099 - val_loss: 0.4733 - val_accuracy: 0.6841\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7082 - val_loss: 0.4650 - val_accuracy: 0.6930\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7207 - val_loss: 0.4693 - val_accuracy: 0.6900\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.4400 - accuracy: 0.7149 - val_loss: 0.4512 - val_accuracy: 0.7013\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7224 - val_loss: 0.4518 - val_accuracy: 0.7028\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7228 - val_loss: 0.4432 - val_accuracy: 0.7112\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7271 - val_loss: 0.4445 - val_accuracy: 0.7112\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7220 - val_loss: 0.4548 - val_accuracy: 0.7043\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7276 - val_loss: 0.4634 - val_accuracy: 0.7038\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7205 - val_loss: 0.4534 - val_accuracy: 0.7063\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7204 - val_loss: 0.4417 - val_accuracy: 0.7132\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7304 - val_loss: 0.4412 - val_accuracy: 0.7186\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 1s 3ms/step - loss: 0.4018 - accuracy: 0.7346 - val_loss: 0.4480 - val_accuracy: 0.7141\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.7289 - val_loss: 0.4361 - val_accuracy: 0.7215\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.7345 - val_loss: 0.4383 - val_accuracy: 0.7240\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.7325 - val_loss: 0.4383 - val_accuracy: 0.7284\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.3950 - accuracy: 0.7396 - val_loss: 0.4378 - val_accuracy: 0.7210\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.7378 - val_loss: 0.4426 - val_accuracy: 0.7235\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.7368 - val_loss: 0.4277 - val_accuracy: 0.7344\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.3854 - accuracy: 0.7396 - val_loss: 0.4289 - val_accuracy: 0.7329\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.7446 - val_loss: 0.4389 - val_accuracy: 0.7240\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.7446 - val_loss: 0.4340 - val_accuracy: 0.7275\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.7453 - val_loss: 0.4340 - val_accuracy: 0.7240\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.7478 - val_loss: 0.4398 - val_accuracy: 0.7275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14189cd60>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce model complexity\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "class_labels = np.unique(Y_train)\n",
    "class_weights = compute_class_weight(class_weight ='balanced',classes=np.unique(Y_train), y=Y_train)\n",
    "class_weights_dict = dict(zip(class_labels, class_weights))\n",
    "# Use class weights during model training\n",
    "model3.fit(X_train, Y_train, epochs=50, batch_size=64, validation_split=0.2, class_weight=class_weights_dict, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 1ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      9523\n",
      "           1       0.19      0.92      0.31       618\n",
      "\n",
      "    accuracy                           0.75     10141\n",
      "   macro avg       0.59      0.83      0.58     10141\n",
      "weighted avg       0.94      0.75      0.82     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[7083 2440]\n",
      " [  51  567]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model3.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/136 [==>...........................] - ETA: 0s "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1s 4ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83      4076\n",
      "           1       0.15      0.73      0.25       271\n",
      "\n",
      "    accuracy                           0.72      4347\n",
      "   macro avg       0.56      0.73      0.54      4347\n",
      "weighted avg       0.92      0.72      0.79      4347\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2950 1126]\n",
      " [  73  198]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "y_pred = model3.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another method, SMOTE to solve the issue.\n",
    "\n",
    "SMOTE can generate synthetic samples for the minority class to balance the class distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "239/239 [==============================] - 1s 6ms/step - loss: 0.2629 - accuracy: 0.8941 - val_loss: 0.2887 - val_accuracy: 0.9178\n",
      "Epoch 2/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.2336 - accuracy: 0.9073 - val_loss: 0.2757 - val_accuracy: 0.9189\n",
      "Epoch 3/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9176 - val_loss: 0.2357 - val_accuracy: 0.9394\n",
      "Epoch 4/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.1998 - accuracy: 0.9229 - val_loss: 0.2043 - val_accuracy: 0.9504\n",
      "Epoch 5/100\n",
      "239/239 [==============================] - 1s 5ms/step - loss: 0.1887 - accuracy: 0.9301 - val_loss: 0.2267 - val_accuracy: 0.9386\n",
      "Epoch 6/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9355 - val_loss: 0.2405 - val_accuracy: 0.9244\n",
      "Epoch 7/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9394 - val_loss: 0.1845 - val_accuracy: 0.9517\n",
      "Epoch 8/100\n",
      "239/239 [==============================] - 1s 6ms/step - loss: 0.1557 - accuracy: 0.9443 - val_loss: 0.1728 - val_accuracy: 0.9522\n",
      "Epoch 9/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.1477 - accuracy: 0.9467 - val_loss: 0.1769 - val_accuracy: 0.9520\n",
      "Epoch 10/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9510 - val_loss: 0.1688 - val_accuracy: 0.9522\n",
      "Epoch 11/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9531 - val_loss: 0.1676 - val_accuracy: 0.9570\n",
      "Epoch 12/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1237 - accuracy: 0.9580 - val_loss: 0.1192 - val_accuracy: 0.9772\n",
      "Epoch 13/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.1181 - accuracy: 0.9590 - val_loss: 0.1168 - val_accuracy: 0.9748\n",
      "Epoch 14/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1149 - accuracy: 0.9611 - val_loss: 0.1294 - val_accuracy: 0.9706\n",
      "Epoch 15/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1072 - accuracy: 0.9638 - val_loss: 0.1395 - val_accuracy: 0.9635\n",
      "Epoch 16/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9653 - val_loss: 0.1093 - val_accuracy: 0.9761\n",
      "Epoch 17/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9674 - val_loss: 0.1046 - val_accuracy: 0.9740\n",
      "Epoch 18/100\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9707 - val_loss: 0.1072 - val_accuracy: 0.9753\n",
      "Epoch 19/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9706 - val_loss: 0.0764 - val_accuracy: 0.9869\n",
      "Epoch 20/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0838 - accuracy: 0.9743 - val_loss: 0.0868 - val_accuracy: 0.9801\n",
      "Epoch 21/100\n",
      "239/239 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9742 - val_loss: 0.0785 - val_accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9735 - val_loss: 0.0927 - val_accuracy: 0.9793\n",
      "Epoch 23/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.0595 - val_accuracy: 0.9882\n",
      "Epoch 24/100\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 0.0838 - val_accuracy: 0.9814\n",
      "Epoch 25/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9801 - val_loss: 0.0614 - val_accuracy: 0.9871\n",
      "Epoch 26/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9781 - val_loss: 0.0576 - val_accuracy: 0.9882\n",
      "Epoch 27/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9796 - val_loss: 0.0501 - val_accuracy: 0.9927\n",
      "Epoch 28/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9820 - val_loss: 0.0601 - val_accuracy: 0.9858\n",
      "Epoch 29/100\n",
      "239/239 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 0.0630 - val_accuracy: 0.9869\n",
      "Epoch 30/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9837 - val_loss: 0.0422 - val_accuracy: 0.9929\n",
      "Epoch 31/100\n",
      "239/239 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 0.9813 - val_loss: 0.0698 - val_accuracy: 0.9853\n",
      "Epoch 32/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9835 - val_loss: 0.0585 - val_accuracy: 0.9882\n",
      "Epoch 33/100\n",
      "239/239 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9856 - val_loss: 0.0559 - val_accuracy: 0.9885\n",
      "Epoch 34/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9851 - val_loss: 0.0684 - val_accuracy: 0.9871\n",
      "Epoch 35/100\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 0.0521 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143a27910>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 1ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      9523\n",
      "           1       0.73      0.99      0.84       618\n",
      "\n",
      "    accuracy                           0.98     10141\n",
      "   macro avg       0.87      0.98      0.91     10141\n",
      "weighted avg       0.98      0.98      0.98     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[9299  224]\n",
      " [   9  609]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      4076\n",
      "           1       0.15      0.20      0.17       271\n",
      "\n",
      "    accuracy                           0.88      4347\n",
      "   macro avg       0.55      0.56      0.55      4347\n",
      "weighted avg       0.90      0.88      0.89      4347\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3768  308]\n",
      " [ 216   55]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall on test set is very low, indicating an overfitting issue.\n",
    "\n",
    "Next step is to solve the issue by restricting the model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "239/239 [==============================] - 2s 4ms/step - loss: 0.6272 - accuracy: 0.6592 - val_loss: 0.7173 - val_accuracy: 0.6008\n",
      "Epoch 2/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7465 - val_loss: 0.6149 - val_accuracy: 0.7669\n",
      "Epoch 3/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.7770 - val_loss: 0.5849 - val_accuracy: 0.7871\n",
      "Epoch 4/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.7908 - val_loss: 0.5501 - val_accuracy: 0.8205\n",
      "Epoch 5/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.7978 - val_loss: 0.5264 - val_accuracy: 0.8375\n",
      "Epoch 6/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8103 - val_loss: 0.4961 - val_accuracy: 0.8546\n",
      "Epoch 7/20\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.3825 - accuracy: 0.8183 - val_loss: 0.5210 - val_accuracy: 0.8323\n",
      "Epoch 8/20\n",
      "239/239 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8255 - val_loss: 0.4776 - val_accuracy: 0.8711\n",
      "Epoch 9/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8304 - val_loss: 0.4607 - val_accuracy: 0.8793\n",
      "Epoch 10/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3560 - accuracy: 0.8341 - val_loss: 0.4502 - val_accuracy: 0.8782\n",
      "Epoch 11/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8393 - val_loss: 0.4564 - val_accuracy: 0.8793\n",
      "Epoch 12/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8441 - val_loss: 0.4351 - val_accuracy: 0.8874\n",
      "Epoch 13/20\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.3407 - accuracy: 0.8450 - val_loss: 0.4038 - val_accuracy: 0.9050\n",
      "Epoch 14/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8484 - val_loss: 0.3941 - val_accuracy: 0.9029\n",
      "Epoch 15/20\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8504 - val_loss: 0.4391 - val_accuracy: 0.8790\n",
      "Epoch 16/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3262 - accuracy: 0.8525 - val_loss: 0.3861 - val_accuracy: 0.9066\n",
      "Epoch 17/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.8609 - val_loss: 0.3828 - val_accuracy: 0.9031\n",
      "Epoch 18/20\n",
      "239/239 [==============================] - 1s 3ms/step - loss: 0.3223 - accuracy: 0.8540 - val_loss: 0.3736 - val_accuracy: 0.9186\n",
      "Epoch 19/20\n",
      "239/239 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.8586 - val_loss: 0.3846 - val_accuracy: 0.9097\n",
      "Epoch 20/20\n",
      "239/239 [==============================] - 1s 4ms/step - loss: 0.3111 - accuracy: 0.8625 - val_loss: 0.3667 - val_accuracy: 0.9186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143834d30>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add dropout, reduce a layer and reduce epochs\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n",
    "model2.fit(X_train_resampled, y_train_resampled, epochs=20, batch_size=64, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 2ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      9523\n",
      "           1       0.33      0.80      0.47       618\n",
      "\n",
      "    accuracy                           0.89     10141\n",
      "   macro avg       0.66      0.85      0.70     10141\n",
      "weighted avg       0.95      0.89      0.91     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[8502 1021]\n",
      " [ 121  497]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model2.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      4076\n",
      "           1       0.17      0.40      0.24       271\n",
      "\n",
      "    accuracy                           0.84      4347\n",
      "   macro avg       0.56      0.64      0.58      4347\n",
      "weighted avg       0.91      0.84      0.87      4347\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3557  519]\n",
      " [ 163  108]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "y_pred = model2.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "115/115 [==============================] - 2s 8ms/step - loss: 0.8596 - accuracy: 0.5193 - val_loss: 0.7169 - val_accuracy: 0.5367\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.5718 - val_loss: 0.6359 - val_accuracy: 0.5942\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6097 - val_loss: 0.6231 - val_accuracy: 0.6150\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6270 - val_loss: 0.5909 - val_accuracy: 0.6435\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6447 - val_loss: 0.5745 - val_accuracy: 0.6522\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.6604 - val_loss: 0.5479 - val_accuracy: 0.6714\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.6823 - val_loss: 0.5413 - val_accuracy: 0.6769\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.6796 - val_loss: 0.5392 - val_accuracy: 0.6780\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.6951 - val_loss: 0.5130 - val_accuracy: 0.6813\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.5083 - accuracy: 0.6940 - val_loss: 0.5120 - val_accuracy: 0.6802\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.6985 - val_loss: 0.5097 - val_accuracy: 0.6840\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.6929 - val_loss: 0.4911 - val_accuracy: 0.6911\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7047 - val_loss: 0.4884 - val_accuracy: 0.6889\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7040 - val_loss: 0.4874 - val_accuracy: 0.6884\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.7071 - val_loss: 0.4913 - val_accuracy: 0.6889\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7107 - val_loss: 0.4810 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7022 - val_loss: 0.4771 - val_accuracy: 0.6911\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7062 - val_loss: 0.4778 - val_accuracy: 0.6972\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4536 - accuracy: 0.7188 - val_loss: 0.4653 - val_accuracy: 0.7021\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7247 - val_loss: 0.4605 - val_accuracy: 0.7048\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7203 - val_loss: 0.4562 - val_accuracy: 0.7125\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7256 - val_loss: 0.4516 - val_accuracy: 0.7147\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7229 - val_loss: 0.4675 - val_accuracy: 0.6999\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.7211 - val_loss: 0.4471 - val_accuracy: 0.7136\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7364 - val_loss: 0.4476 - val_accuracy: 0.7152\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7334 - val_loss: 0.4416 - val_accuracy: 0.7207\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4201 - accuracy: 0.7303 - val_loss: 0.4443 - val_accuracy: 0.7191\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.7340 - val_loss: 0.4674 - val_accuracy: 0.7065\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.7273 - val_loss: 0.4548 - val_accuracy: 0.7130\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7301 - val_loss: 0.4521 - val_accuracy: 0.7169\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.4142 - accuracy: 0.7349 - val_loss: 0.4414 - val_accuracy: 0.7180\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4055 - accuracy: 0.7285 - val_loss: 0.4482 - val_accuracy: 0.7152\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7368 - val_loss: 0.4445 - val_accuracy: 0.7202\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.3986 - accuracy: 0.7499 - val_loss: 0.4328 - val_accuracy: 0.7256\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.4056 - accuracy: 0.7429 - val_loss: 0.4461 - val_accuracy: 0.7163\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.4085 - accuracy: 0.7418 - val_loss: 0.4485 - val_accuracy: 0.7147\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.3918 - accuracy: 0.7421 - val_loss: 0.4422 - val_accuracy: 0.7147\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3956 - accuracy: 0.7397 - val_loss: 0.4302 - val_accuracy: 0.7278\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.7503 - val_loss: 0.4414 - val_accuracy: 0.7306\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.7501 - val_loss: 0.4344 - val_accuracy: 0.7327\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3995 - accuracy: 0.7411 - val_loss: 0.4417 - val_accuracy: 0.7256\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.7493 - val_loss: 0.4360 - val_accuracy: 0.7317\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3841 - accuracy: 0.7521 - val_loss: 0.4230 - val_accuracy: 0.7366\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.7564 - val_loss: 0.4313 - val_accuracy: 0.7333\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.7564 - val_loss: 0.4288 - val_accuracy: 0.7388\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.7547 - val_loss: 0.4197 - val_accuracy: 0.7399\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.7592 - val_loss: 0.4387 - val_accuracy: 0.7278\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.3718 - accuracy: 0.7540 - val_loss: 0.4251 - val_accuracy: 0.7437\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.7596 - val_loss: 0.4250 - val_accuracy: 0.7448\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.7612 - val_loss: 0.4189 - val_accuracy: 0.7470\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 3s 11ms/step - loss: 0.8380 - accuracy: 0.6707 - val_loss: 0.6298 - val_accuracy: 0.6172\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.7154 - accuracy: 0.5964 - val_loss: 0.6267 - val_accuracy: 0.6145\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 1s 11ms/step - loss: 0.6563 - accuracy: 0.6203 - val_loss: 0.6282 - val_accuracy: 0.6145\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5970 - accuracy: 0.6240 - val_loss: 0.5766 - val_accuracy: 0.6435\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.5873 - accuracy: 0.6596 - val_loss: 0.5633 - val_accuracy: 0.6599\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.6606 - val_loss: 0.5572 - val_accuracy: 0.6605\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.6731 - val_loss: 0.5511 - val_accuracy: 0.6616\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.6863 - val_loss: 0.5406 - val_accuracy: 0.6627\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.6855 - val_loss: 0.5141 - val_accuracy: 0.6763\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.6939 - val_loss: 0.5110 - val_accuracy: 0.6758\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.6970 - val_loss: 0.5037 - val_accuracy: 0.6807\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7058 - val_loss: 0.4846 - val_accuracy: 0.6867\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.4700 - accuracy: 0.7106 - val_loss: 0.4909 - val_accuracy: 0.6851\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7081 - val_loss: 0.4850 - val_accuracy: 0.6878\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7085 - val_loss: 0.4778 - val_accuracy: 0.6889\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7161 - val_loss: 0.4676 - val_accuracy: 0.6966\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7281 - val_loss: 0.4648 - val_accuracy: 0.6961\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7191 - val_loss: 0.4540 - val_accuracy: 0.7015\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7278 - val_loss: 0.4563 - val_accuracy: 0.7048\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7328 - val_loss: 0.4478 - val_accuracy: 0.7070\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.7309 - val_loss: 0.4623 - val_accuracy: 0.6999\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7276 - val_loss: 0.4568 - val_accuracy: 0.7037\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7399 - val_loss: 0.4631 - val_accuracy: 0.7032\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7265 - val_loss: 0.4607 - val_accuracy: 0.7043\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7252 - val_loss: 0.4490 - val_accuracy: 0.7152\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 2s 5ms/step - loss: 0.8489 - accuracy: 0.6654 - val_loss: 0.6412 - val_accuracy: 0.5964\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.5951 - val_loss: 0.6558 - val_accuracy: 0.5471\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.6579 - accuracy: 0.5779 - val_loss: 0.6372 - val_accuracy: 0.5613\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6053 - val_loss: 0.6090 - val_accuracy: 0.6008\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.6314 - val_loss: 0.6005 - val_accuracy: 0.6150\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.6498 - val_loss: 0.5609 - val_accuracy: 0.6495\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.6740 - val_loss: 0.5584 - val_accuracy: 0.6512\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.6898 - val_loss: 0.5356 - val_accuracy: 0.6627\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.6848 - val_loss: 0.5177 - val_accuracy: 0.6736\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.6910 - val_loss: 0.5127 - val_accuracy: 0.6785\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.6978 - val_loss: 0.4998 - val_accuracy: 0.6802\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7035 - val_loss: 0.4918 - val_accuracy: 0.6824\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7096 - val_loss: 0.4836 - val_accuracy: 0.6878\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7048 - val_loss: 0.4868 - val_accuracy: 0.6873\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7080 - val_loss: 0.4731 - val_accuracy: 0.6961\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7235 - val_loss: 0.4715 - val_accuracy: 0.6955\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7169 - val_loss: 0.4835 - val_accuracy: 0.6873\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.7115 - val_loss: 0.4716 - val_accuracy: 0.6928\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7154 - val_loss: 0.4581 - val_accuracy: 0.6977\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7250 - val_loss: 0.4627 - val_accuracy: 0.6988\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7232 - val_loss: 0.4496 - val_accuracy: 0.7037\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.7214 - val_loss: 0.4675 - val_accuracy: 0.6950\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7233 - val_loss: 0.4497 - val_accuracy: 0.7087\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7311 - val_loss: 0.4601 - val_accuracy: 0.7037\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7357 - val_loss: 0.4531 - val_accuracy: 0.7103\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7337 - val_loss: 0.4570 - val_accuracy: 0.7076\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 2s 6ms/step - loss: 0.8494 - accuracy: 0.5643 - val_loss: 0.6912 - val_accuracy: 0.5455\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.5665 - val_loss: 0.6457 - val_accuracy: 0.5701\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.5950 - val_loss: 0.6152 - val_accuracy: 0.6079\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6261 - val_loss: 0.5765 - val_accuracy: 0.6418\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.6448 - val_loss: 0.5543 - val_accuracy: 0.6583\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.5371 - accuracy: 0.6743 - val_loss: 0.5235 - val_accuracy: 0.6807\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.5310 - accuracy: 0.6869 - val_loss: 0.5222 - val_accuracy: 0.6802\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.6989 - val_loss: 0.5171 - val_accuracy: 0.6813\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.6976 - val_loss: 0.5081 - val_accuracy: 0.6829\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7021 - val_loss: 0.4980 - val_accuracy: 0.6851\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7083 - val_loss: 0.4905 - val_accuracy: 0.6884\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7183 - val_loss: 0.4813 - val_accuracy: 0.6955\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7170 - val_loss: 0.4759 - val_accuracy: 0.6922\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7207 - val_loss: 0.4796 - val_accuracy: 0.6906\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7155 - val_loss: 0.4684 - val_accuracy: 0.6928\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7143 - val_loss: 0.4716 - val_accuracy: 0.6922\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7214 - val_loss: 0.4649 - val_accuracy: 0.6917\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7291 - val_loss: 0.4562 - val_accuracy: 0.6982\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7259 - val_loss: 0.4493 - val_accuracy: 0.7076\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7340 - val_loss: 0.4509 - val_accuracy: 0.7032\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7248 - val_loss: 0.4502 - val_accuracy: 0.7065\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.7233 - val_loss: 0.4528 - val_accuracy: 0.7032\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7300 - val_loss: 0.4529 - val_accuracy: 0.7070\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7374 - val_loss: 0.4438 - val_accuracy: 0.7114\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4102 - accuracy: 0.7355 - val_loss: 0.4351 - val_accuracy: 0.7163\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7404 - val_loss: 0.4262 - val_accuracy: 0.7229\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.7454 - val_loss: 0.4289 - val_accuracy: 0.7218\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7515 - val_loss: 0.4361 - val_accuracy: 0.7212\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.7461 - val_loss: 0.4391 - val_accuracy: 0.7147\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4008 - accuracy: 0.7459 - val_loss: 0.4232 - val_accuracy: 0.7295\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.7509 - val_loss: 0.4354 - val_accuracy: 0.7223\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.7511 - val_loss: 0.4089 - val_accuracy: 0.7415\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.7562 - val_loss: 0.4094 - val_accuracy: 0.7426\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.7541 - val_loss: 0.4298 - val_accuracy: 0.7300\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.7498 - val_loss: 0.4141 - val_accuracy: 0.7377\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.7520 - val_loss: 0.4106 - val_accuracy: 0.7404\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3913 - accuracy: 0.7559 - val_loss: 0.4304 - val_accuracy: 0.7267\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 2s 6ms/step - loss: 0.8033 - accuracy: 0.5988 - val_loss: 0.6893 - val_accuracy: 0.5613\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5872 - val_loss: 0.6635 - val_accuracy: 0.5778\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.6329 - accuracy: 0.6120 - val_loss: 0.6120 - val_accuracy: 0.6177\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.6353 - val_loss: 0.5795 - val_accuracy: 0.6435\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.6661 - val_loss: 0.5546 - val_accuracy: 0.6616\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5491 - accuracy: 0.6677 - val_loss: 0.5493 - val_accuracy: 0.6616\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.6950 - val_loss: 0.5457 - val_accuracy: 0.6670\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.6879 - val_loss: 0.5427 - val_accuracy: 0.6692\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.6996 - val_loss: 0.5041 - val_accuracy: 0.6873\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7144 - val_loss: 0.5077 - val_accuracy: 0.6862\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7125 - val_loss: 0.4910 - val_accuracy: 0.6928\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7095 - val_loss: 0.5012 - val_accuracy: 0.6862\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.7121 - val_loss: 0.4892 - val_accuracy: 0.6917\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7165 - val_loss: 0.4738 - val_accuracy: 0.6999\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7221 - val_loss: 0.4729 - val_accuracy: 0.6988\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7217 - val_loss: 0.4719 - val_accuracy: 0.6972\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7304 - val_loss: 0.4753 - val_accuracy: 0.7010\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7261 - val_loss: 0.4687 - val_accuracy: 0.7032\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7310 - val_loss: 0.4722 - val_accuracy: 0.7021\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.7254 - val_loss: 0.4684 - val_accuracy: 0.7015\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7376 - val_loss: 0.4725 - val_accuracy: 0.6988\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7261 - val_loss: 0.4591 - val_accuracy: 0.7054\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7326 - val_loss: 0.4393 - val_accuracy: 0.7196\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7435 - val_loss: 0.4348 - val_accuracy: 0.7207\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7507 - val_loss: 0.4525 - val_accuracy: 0.7114\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7447 - val_loss: 0.4497 - val_accuracy: 0.7108\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7391 - val_loss: 0.4427 - val_accuracy: 0.7196\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4110 - accuracy: 0.7461 - val_loss: 0.4377 - val_accuracy: 0.7218\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.7507 - val_loss: 0.4411 - val_accuracy: 0.7202\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 2s 7ms/step - loss: 0.9262 - accuracy: 0.6511 - val_loss: 0.6328 - val_accuracy: 0.6281\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.6021 - val_loss: 0.6352 - val_accuracy: 0.6177\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6164 - val_loss: 0.6169 - val_accuracy: 0.6254\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.6327 - val_loss: 0.5762 - val_accuracy: 0.6555\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.6602 - val_loss: 0.5611 - val_accuracy: 0.6610\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.6661 - val_loss: 0.5326 - val_accuracy: 0.6736\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.6836 - val_loss: 0.5302 - val_accuracy: 0.6698\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.6894 - val_loss: 0.5231 - val_accuracy: 0.6774\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.6920 - val_loss: 0.5128 - val_accuracy: 0.6769\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7011 - val_loss: 0.5133 - val_accuracy: 0.6747\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.6911 - val_loss: 0.5145 - val_accuracy: 0.6731\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4812 - accuracy: 0.6963 - val_loss: 0.4977 - val_accuracy: 0.6862\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.6995 - val_loss: 0.5013 - val_accuracy: 0.6824\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7120 - val_loss: 0.5019 - val_accuracy: 0.6769\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.6965 - val_loss: 0.4781 - val_accuracy: 0.6857\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7184 - val_loss: 0.4807 - val_accuracy: 0.6862\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7165 - val_loss: 0.4786 - val_accuracy: 0.6928\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7136 - val_loss: 0.4780 - val_accuracy: 0.6862\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4326 - accuracy: 0.7244 - val_loss: 0.4694 - val_accuracy: 0.6961\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7241 - val_loss: 0.4547 - val_accuracy: 0.7015\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4356 - accuracy: 0.7254 - val_loss: 0.4702 - val_accuracy: 0.6939\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7298 - val_loss: 0.4629 - val_accuracy: 0.6982\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7299 - val_loss: 0.4672 - val_accuracy: 0.6922\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7329 - val_loss: 0.4582 - val_accuracy: 0.7081\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.7377 - val_loss: 0.4543 - val_accuracy: 0.7114\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.7420 - val_loss: 0.4487 - val_accuracy: 0.7147\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7384 - val_loss: 0.4445 - val_accuracy: 0.7169\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7307 - val_loss: 0.4490 - val_accuracy: 0.7136\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.7337 - val_loss: 0.4417 - val_accuracy: 0.7212\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.7414 - val_loss: 0.4307 - val_accuracy: 0.7284\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.7530 - val_loss: 0.4437 - val_accuracy: 0.7185\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.7458 - val_loss: 0.4407 - val_accuracy: 0.7245\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.7477 - val_loss: 0.4437 - val_accuracy: 0.7218\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.7513 - val_loss: 0.4256 - val_accuracy: 0.7366\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.7551 - val_loss: 0.4331 - val_accuracy: 0.7267\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.7533 - val_loss: 0.4240 - val_accuracy: 0.7327\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.7574 - val_loss: 0.4342 - val_accuracy: 0.7278\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3858 - accuracy: 0.7513 - val_loss: 0.4289 - val_accuracy: 0.7284\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.7626 - val_loss: 0.4309 - val_accuracy: 0.7262\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.7504 - val_loss: 0.4368 - val_accuracy: 0.7218\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.7488 - val_loss: 0.4355 - val_accuracy: 0.7262\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 4s 28ms/step - loss: 0.8325 - accuracy: 0.5190 - val_loss: 0.7038 - val_accuracy: 0.5394\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.7015 - accuracy: 0.5683 - val_loss: 0.6268 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6148 - val_loss: 0.5956 - val_accuracy: 0.6227\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6494 - val_loss: 0.5707 - val_accuracy: 0.6451\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.6732 - val_loss: 0.5398 - val_accuracy: 0.6731\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.6795 - val_loss: 0.5407 - val_accuracy: 0.6681\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.6795 - val_loss: 0.5401 - val_accuracy: 0.6698\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.6906 - val_loss: 0.5223 - val_accuracy: 0.6731\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.6950 - val_loss: 0.5122 - val_accuracy: 0.6752\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.6947 - val_loss: 0.4895 - val_accuracy: 0.6796\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7099 - val_loss: 0.4970 - val_accuracy: 0.6791\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7014 - val_loss: 0.4809 - val_accuracy: 0.6873\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7147 - val_loss: 0.4815 - val_accuracy: 0.6802\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7168 - val_loss: 0.4902 - val_accuracy: 0.6758\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7003 - val_loss: 0.4907 - val_accuracy: 0.6785\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7121 - val_loss: 0.4851 - val_accuracy: 0.6807\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7141 - val_loss: 0.4766 - val_accuracy: 0.6867\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7168 - val_loss: 0.4663 - val_accuracy: 0.6955\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.4491 - accuracy: 0.7198 - val_loss: 0.4554 - val_accuracy: 0.6999\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7284 - val_loss: 0.4578 - val_accuracy: 0.6993\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7173 - val_loss: 0.4531 - val_accuracy: 0.6988\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7218 - val_loss: 0.4645 - val_accuracy: 0.6955\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4271 - accuracy: 0.7270 - val_loss: 0.4565 - val_accuracy: 0.6966\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7369 - val_loss: 0.4615 - val_accuracy: 0.6966\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4356 - accuracy: 0.7183 - val_loss: 0.4554 - val_accuracy: 0.6933\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7274 - val_loss: 0.4445 - val_accuracy: 0.7037\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7298 - val_loss: 0.4571 - val_accuracy: 0.6966\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.7217 - val_loss: 0.4452 - val_accuracy: 0.7032\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7350 - val_loss: 0.4435 - val_accuracy: 0.7097\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4248 - accuracy: 0.7310 - val_loss: 0.4501 - val_accuracy: 0.7097\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.7274 - val_loss: 0.4384 - val_accuracy: 0.7108\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.7335 - val_loss: 0.4372 - val_accuracy: 0.7136\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4042 - accuracy: 0.7315 - val_loss: 0.4285 - val_accuracy: 0.7174\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.7432 - val_loss: 0.4560 - val_accuracy: 0.7032\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4016 - accuracy: 0.7377 - val_loss: 0.4340 - val_accuracy: 0.7125\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.7350 - val_loss: 0.4375 - val_accuracy: 0.7114\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.7461 - val_loss: 0.4327 - val_accuracy: 0.7130\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.7417 - val_loss: 0.4243 - val_accuracy: 0.7212\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.7509 - val_loss: 0.4309 - val_accuracy: 0.7180\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3864 - accuracy: 0.7541 - val_loss: 0.4314 - val_accuracy: 0.7207\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3938 - accuracy: 0.7420 - val_loss: 0.4290 - val_accuracy: 0.7251\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.7489 - val_loss: 0.4255 - val_accuracy: 0.7262\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.7547 - val_loss: 0.4203 - val_accuracy: 0.7284\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3716 - accuracy: 0.7474 - val_loss: 0.4225 - val_accuracy: 0.7333\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3844 - accuracy: 0.7510 - val_loss: 0.4238 - val_accuracy: 0.7317\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.7530 - val_loss: 0.4246 - val_accuracy: 0.7306\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.7554 - val_loss: 0.4067 - val_accuracy: 0.7437\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.7529 - val_loss: 0.4175 - val_accuracy: 0.7366\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.7603 - val_loss: 0.4177 - val_accuracy: 0.7382\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.7632 - val_loss: 0.4123 - val_accuracy: 0.7442\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.8016 - accuracy: 0.5117 - val_loss: 0.7168 - val_accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.5736 - val_loss: 0.6533 - val_accuracy: 0.5838\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6227 - val_loss: 0.6164 - val_accuracy: 0.6134\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6377 - val_loss: 0.5973 - val_accuracy: 0.6281\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.6524 - val_loss: 0.5790 - val_accuracy: 0.6446\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.6570 - val_loss: 0.5530 - val_accuracy: 0.6621\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.6750 - val_loss: 0.5381 - val_accuracy: 0.6643\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.6811 - val_loss: 0.5215 - val_accuracy: 0.6725\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.6931 - val_loss: 0.5112 - val_accuracy: 0.6742\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.5014 - accuracy: 0.7007 - val_loss: 0.5293 - val_accuracy: 0.6676\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.6998 - val_loss: 0.5003 - val_accuracy: 0.6774\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.6957 - val_loss: 0.4870 - val_accuracy: 0.6824\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7099 - val_loss: 0.4935 - val_accuracy: 0.6769\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.7077 - val_loss: 0.4898 - val_accuracy: 0.6791\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7020 - val_loss: 0.4924 - val_accuracy: 0.6769\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7081 - val_loss: 0.4804 - val_accuracy: 0.6818\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7035 - val_loss: 0.4832 - val_accuracy: 0.6802\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7117 - val_loss: 0.4773 - val_accuracy: 0.6878\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4514 - accuracy: 0.7188 - val_loss: 0.4846 - val_accuracy: 0.6862\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7158 - val_loss: 0.4704 - val_accuracy: 0.6911\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7174 - val_loss: 0.4606 - val_accuracy: 0.7015\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7173 - val_loss: 0.4699 - val_accuracy: 0.6933\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7144 - val_loss: 0.4619 - val_accuracy: 0.6988\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.7251 - val_loss: 0.4799 - val_accuracy: 0.6911\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7251 - val_loss: 0.4663 - val_accuracy: 0.6982\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7262 - val_loss: 0.4569 - val_accuracy: 0.7076\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4269 - accuracy: 0.7310 - val_loss: 0.4619 - val_accuracy: 0.7070\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7194 - val_loss: 0.4683 - val_accuracy: 0.7065\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.4171 - accuracy: 0.7347 - val_loss: 0.4490 - val_accuracy: 0.7141\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7335 - val_loss: 0.4547 - val_accuracy: 0.7076\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7348 - val_loss: 0.4535 - val_accuracy: 0.7108\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.7343 - val_loss: 0.4550 - val_accuracy: 0.7087\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.7369 - val_loss: 0.4632 - val_accuracy: 0.7108\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4151 - accuracy: 0.7366 - val_loss: 0.4596 - val_accuracy: 0.7087\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.7787 - accuracy: 0.5339 - val_loss: 0.6989 - val_accuracy: 0.5126\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7326 - accuracy: 0.5414 - val_loss: 0.6451 - val_accuracy: 0.5427\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.5824 - val_loss: 0.5994 - val_accuracy: 0.6002\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6291 - val_loss: 0.5805 - val_accuracy: 0.6314\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.6346 - val_loss: 0.5604 - val_accuracy: 0.6577\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5658 - accuracy: 0.6611 - val_loss: 0.5387 - val_accuracy: 0.6774\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.6813 - val_loss: 0.5470 - val_accuracy: 0.6692\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.6776 - val_loss: 0.5148 - val_accuracy: 0.6796\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.6936 - val_loss: 0.5123 - val_accuracy: 0.6736\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4906 - accuracy: 0.6914 - val_loss: 0.4994 - val_accuracy: 0.6785\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7025 - val_loss: 0.4890 - val_accuracy: 0.6796\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7009 - val_loss: 0.4689 - val_accuracy: 0.6906\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7111 - val_loss: 0.4703 - val_accuracy: 0.6917\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.6976 - val_loss: 0.4825 - val_accuracy: 0.6835\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.6931 - val_loss: 0.4811 - val_accuracy: 0.6851\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4534 - accuracy: 0.7042 - val_loss: 0.4588 - val_accuracy: 0.6993\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7069 - val_loss: 0.4623 - val_accuracy: 0.6961\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.7147 - val_loss: 0.4588 - val_accuracy: 0.6928\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7137 - val_loss: 0.4512 - val_accuracy: 0.6982\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7177 - val_loss: 0.4496 - val_accuracy: 0.6977\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7226 - val_loss: 0.4455 - val_accuracy: 0.7010\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4336 - accuracy: 0.7210 - val_loss: 0.4480 - val_accuracy: 0.6988\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7258 - val_loss: 0.4562 - val_accuracy: 0.6939\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7162 - val_loss: 0.4418 - val_accuracy: 0.7043\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7287 - val_loss: 0.4321 - val_accuracy: 0.7114\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4300 - accuracy: 0.7251 - val_loss: 0.4457 - val_accuracy: 0.7010\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4238 - accuracy: 0.7266 - val_loss: 0.4330 - val_accuracy: 0.7119\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7341 - val_loss: 0.4312 - val_accuracy: 0.7141\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7367 - val_loss: 0.4406 - val_accuracy: 0.7125\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7283 - val_loss: 0.4311 - val_accuracy: 0.7158\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.7318 - val_loss: 0.4315 - val_accuracy: 0.7174\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7352 - val_loss: 0.4163 - val_accuracy: 0.7327\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.7469 - val_loss: 0.4227 - val_accuracy: 0.7245\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.7407 - val_loss: 0.4180 - val_accuracy: 0.7267\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.7450 - val_loss: 0.4178 - val_accuracy: 0.7300\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.7418 - val_loss: 0.4248 - val_accuracy: 0.7256\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.7392 - val_loss: 0.4162 - val_accuracy: 0.7322\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.3983 - accuracy: 0.7404 - val_loss: 0.4285 - val_accuracy: 0.7191\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.7366 - val_loss: 0.4199 - val_accuracy: 0.7295\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.7454 - val_loss: 0.4173 - val_accuracy: 0.7360\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.7430 - val_loss: 0.4245 - val_accuracy: 0.7322\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3871 - accuracy: 0.7473 - val_loss: 0.4182 - val_accuracy: 0.7382\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.9208 - accuracy: 0.6907 - val_loss: 0.6185 - val_accuracy: 0.6260\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.6083 - val_loss: 0.6541 - val_accuracy: 0.5915\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.6083 - val_loss: 0.6416 - val_accuracy: 0.6013\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6181 - val_loss: 0.6066 - val_accuracy: 0.6271\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6443 - val_loss: 0.5726 - val_accuracy: 0.6484\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.6637 - val_loss: 0.5666 - val_accuracy: 0.6501\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.6689 - val_loss: 0.5622 - val_accuracy: 0.6501\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.6826 - val_loss: 0.5338 - val_accuracy: 0.6610\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.6879 - val_loss: 0.5420 - val_accuracy: 0.6616\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.6820 - val_loss: 0.5222 - val_accuracy: 0.6676\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.6977 - val_loss: 0.5029 - val_accuracy: 0.6698\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.6926 - val_loss: 0.5106 - val_accuracy: 0.6692\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.6966 - val_loss: 0.4972 - val_accuracy: 0.6752\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.6987 - val_loss: 0.4834 - val_accuracy: 0.6867\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4559 - accuracy: 0.7072 - val_loss: 0.4808 - val_accuracy: 0.6840\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7063 - val_loss: 0.4741 - val_accuracy: 0.6884\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7051 - val_loss: 0.4859 - val_accuracy: 0.6818\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7005 - val_loss: 0.4817 - val_accuracy: 0.6807\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7073 - val_loss: 0.4876 - val_accuracy: 0.6802\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4385 - accuracy: 0.7084 - val_loss: 0.4724 - val_accuracy: 0.6835\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7115 - val_loss: 0.4693 - val_accuracy: 0.6862\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7133 - val_loss: 0.4663 - val_accuracy: 0.6900\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.7217 - val_loss: 0.4725 - val_accuracy: 0.6857\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.4336 - accuracy: 0.7077 - val_loss: 0.4643 - val_accuracy: 0.6900\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 1s 9ms/step - loss: 0.4161 - accuracy: 0.7176 - val_loss: 0.4486 - val_accuracy: 0.7048\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.7274 - val_loss: 0.4585 - val_accuracy: 0.6950\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 1s 11ms/step - loss: 0.4144 - accuracy: 0.7251 - val_loss: 0.4559 - val_accuracy: 0.6972\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7243 - val_loss: 0.4637 - val_accuracy: 0.6950\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7278 - val_loss: 0.4460 - val_accuracy: 0.7054\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7270 - val_loss: 0.4497 - val_accuracy: 0.7043\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7231 - val_loss: 0.4462 - val_accuracy: 0.7097\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4003 - accuracy: 0.7388 - val_loss: 0.4543 - val_accuracy: 0.7043\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7285 - val_loss: 0.4586 - val_accuracy: 0.6993\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.7288 - val_loss: 0.4549 - val_accuracy: 0.7026\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Average Optimal Threshold: 0.6528012\n",
      "Average F1 Score at Optimal Threshold: 0.2900721945271713\n"
     ]
    }
   ],
   "source": [
    "# Build a simple neural network model\n",
    "def build_model():\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    model3.add(Dense(1, activation='sigmoid'))\n",
    "    model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model3\n",
    "\n",
    "# Initialize StratifiedKFold for cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "optimal_thresholds = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validated predictions\n",
    "for train_index, test_index in kfold.split(X_train, Y_train):\n",
    "    x_train, X_validation = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_validation = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "    class_labels = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(class_weight ='balanced',classes=np.unique(y_train), y=y_train)\n",
    "    class_weights_dict = dict(zip(class_labels, class_weights))\n",
    "    # Use class weights during model training\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.2, class_weight=class_weights_dict, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "    # Predict probabilities on the test set\n",
    "    y_pred_prob = model.predict(X_validation)\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_validation, y_pred_prob)\n",
    "\n",
    "    # Calculate F1 score for each threshold\n",
    "    f1_scores_fold = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Handle cases where both precision and recall are zero\n",
    "    f1_scores_fold = np.nan_to_num(f1_scores_fold, nan=0.0)\n",
    "\n",
    "    # Find the threshold that maximizes F1 score\n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores_fold)]\n",
    "\n",
    "    # Append results to lists\n",
    "    optimal_thresholds.append(optimal_threshold)\n",
    "    f1_scores.append(np.max(f1_scores_fold))\n",
    "\n",
    "# Calculate average optimal threshold and F1 score\n",
    "avg_optimal_threshold = np.mean(optimal_thresholds)\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "\n",
    "# Print average optimal threshold and F1 score\n",
    "print(\"Average Optimal Threshold:\", avg_optimal_threshold)\n",
    "print(\"Average F1 Score at Optimal Threshold:\", avg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/127 [==============================] - 2s 5ms/step - loss: 0.8777 - accuracy: 0.5068 - val_loss: 0.7087 - val_accuracy: 0.5589\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5907 - val_loss: 0.6394 - val_accuracy: 0.6008\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.6261 - accuracy: 0.6112 - val_loss: 0.6012 - val_accuracy: 0.6333\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.6370 - val_loss: 0.5884 - val_accuracy: 0.6407\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.6493 - val_loss: 0.5559 - val_accuracy: 0.6555\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.6731 - val_loss: 0.5353 - val_accuracy: 0.6629\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.6641 - val_loss: 0.5222 - val_accuracy: 0.6718\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.6774 - val_loss: 0.5011 - val_accuracy: 0.6826\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.6850 - val_loss: 0.5312 - val_accuracy: 0.6644\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.6808 - val_loss: 0.5199 - val_accuracy: 0.6683\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.6799 - val_loss: 0.5162 - val_accuracy: 0.6673\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.6943 - val_loss: 0.4983 - val_accuracy: 0.6767\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.6956 - val_loss: 0.4827 - val_accuracy: 0.6856\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7002 - val_loss: 0.4739 - val_accuracy: 0.6880\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.6964 - val_loss: 0.4862 - val_accuracy: 0.6792\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.7017 - val_loss: 0.4717 - val_accuracy: 0.6865\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7038 - val_loss: 0.4830 - val_accuracy: 0.6796\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.4542 - accuracy: 0.6995 - val_loss: 0.4735 - val_accuracy: 0.6856\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7051 - val_loss: 0.4815 - val_accuracy: 0.6811\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7057 - val_loss: 0.4863 - val_accuracy: 0.6792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143665330>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "class_labels = np.unique(Y_train)\n",
    "class_weights = compute_class_weight(class_weight ='balanced',classes=np.unique(Y_train), y=Y_train)\n",
    "class_weights_dict = dict(zip(class_labels, class_weights))\n",
    "# Use class weights during model training\n",
    "model3.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.2, class_weight=class_weights_dict, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/317 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 2s 5ms/step\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      9523\n",
      "           1       0.22      0.75      0.34       618\n",
      "\n",
      "    accuracy                           0.82     10141\n",
      "   macro avg       0.60      0.79      0.62     10141\n",
      "weighted avg       0.93      0.82      0.86     10141\n",
      "\n",
      "Training Confusion Matrix:\n",
      " [[7869 1654]\n",
      " [ 156  462]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_pred = model3.predict(X_train)\n",
    "# set threshold to be 0.64\n",
    "y_train_pred = (y_train_pred > 0.65).astype(int)\n",
    "\n",
    "# Display training classification report and confusion matrix\n",
    "print(\"Training Classification Report:\\n\", classification_report(Y_train, y_train_pred))\n",
    "print(\"Training Confusion Matrix:\\n\", confusion_matrix(Y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/136 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1s 4ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88      4076\n",
      "           1       0.16      0.58      0.26       271\n",
      "\n",
      "    accuracy                           0.79      4347\n",
      "   macro avg       0.57      0.69      0.57      4347\n",
      "weighted avg       0.92      0.79      0.84      4347\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3283  793]\n",
      " [ 115  156]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set using the best parameters\n",
    "y_pred = model3.predict(X_test)\n",
    "y_pred = (y_pred > 0.65).astype(int)\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
